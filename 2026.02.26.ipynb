{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8eddfbb-7a37-4128-8ae1-5111f059c092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n", 
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "rnn_layer = nn.RNN(input_size=5, hidden_size=2, num_layers=1, batch_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccc38a48-57db-4638-abe6-85b45e5ded2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_hh = rnn_layer.weight_hh_l0\n",
    "w_xh = rnn_layer.weight_ih_l0\n",
    "b_hh = rnn_layer.bias_hh_l0\n",
    "b_xh = rnn_layer.bias_ih_l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8df484df-7666-4517-a582-f6b0b13cc391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_xh 크기: torch.Size([2, 5])\n",
      "W_hh 크기: torch.Size([2, 2])\n",
      "b_xh 크기: torch.Size([2])\n",
      "b_hh 크기: torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "print('W_xh 크기:', w_xh.shape)\n",
    "print('W_hh 크기:', w_hh.shape)\n",
    "print('b_xh 크기:', b_xh.shape)\n",
    "print('b_hh 크기:', b_hh.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1645c09-a365-41bb-abe3-0f5ea8695c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_seq = torch.tensor([[1.0]*5, [2.0]*5, [3.0]*5]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c25138cc-e5b1-4601-92a7-92e22662d12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [2., 2., 2., 2., 2.],\n",
       "        [3., 3., 3., 3., 3.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I am boy\n",
    "x_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d13a98e-b6b9-4d4e-958c-c085433e45ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "output, hn = rnn_layer(torch.reshape(x_seq, (1, 3, 5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88e36926-95d9-4e62-8a1f-917ac0662451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.3520,  0.5253],\n",
      "         [-0.6842,  0.7607],\n",
      "         [-0.8649,  0.9047]]], grad_fn=<TransposeBackward1>)\n",
      "tensor([[[-0.8649,  0.9047]]], grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(output)\n",
    "print(hn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "617c39d3-8292-4d36-9c22-d102dab89f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 스템 0 -> 입력 [[1. 1. 1. 1. 1.]]\n",
      "은닉  -> tensor([[-0.4702,  0.5864]], grad_fn=<AddBackward0>)\n",
      " 출력(수동) --> [[-0.3519801   0.52525216]]   \n",
      " RNN 출력 --> [[-0.3519801   0.52525216]]   \n",
      "타입 스템 1 -> 입력 [[2. 2. 2. 2. 2.]]\n",
      "은닉  -> tensor([[-0.8888,  1.2364]], grad_fn=<AddBackward0>)\n",
      " 출력(수동) --> [[-0.68424344  0.76074266]]   \n",
      " RNN 출력 --> [[-0.68424344  0.76074266]]   \n",
      "타입 스템 2 -> 입력 [[3. 3. 3. 3. 3.]]\n",
      "은닉  -> tensor([[-1.3075,  1.8865]], grad_fn=<AddBackward0>)\n",
      " 출력(수동) --> [[-0.8649416   0.90466356]]   \n",
      " RNN 출력 --> [[-0.8649416   0.90466356]]   \n"
     ]
    }
   ],
   "source": [
    "out_man = []\n",
    "for t in range(3):\n",
    "    xt = torch.reshape(x_seq[t], (1,5))\n",
    "    print(f\"타입 스템 {t} -> 입력 {xt.numpy()}\")\n",
    "\n",
    "    ht = torch.matmul(xt, torch.transpose(w_xh, 0, 1)) + b_xh\n",
    "    print(f'은닉  -> {ht}')\n",
    "\n",
    "    if t>0:\n",
    "        prev_h = out_man[t-1]\n",
    "    else:\n",
    "        prev_h = torch.zeros((ht.shape))\n",
    "\n",
    "    ot = ht + torch.matmul(prev_h, torch.transpose(w_hh, 0, 1)) + b_hh\n",
    "    ot = torch.tanh(ot)\n",
    "    out_man.append(ot)\n",
    "    print( f\" 출력(수동) --> {ot.detach().numpy()}   \")\n",
    "    print( f\" RNN 출력 --> {output[:, t].detach().numpy()}   \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5a810d5-9884-421d-af90-5ef1317d6b48",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-4.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from datasets) (2.3.5)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.6.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.19 (from datasets)\n",
      "  Downloading multiprocess-0.70.18-py312-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: fsspec<=2026.2.0,>=2023.1.0 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from fsspec[http]<=2026.2.0,>=2023.1.0->datasets) (2025.10.0)\n",
      "Collecting huggingface-hub<2.0,>=0.25.0 (from datasets)\n",
      "  Downloading huggingface_hub-1.4.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from fsspec[http]<=2026.2.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from httpx<1.0.0->datasets) (4.10.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub<2.0,>=0.25.0->datasets)\n",
      "  Downloading hf_xet-1.3.1-cp37-abi3-win_amd64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: shellingham in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (0.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2026.2.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2026.2.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2026.2.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2026.2.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2026.2.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2026.2.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2026.2.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2.6.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\playdata2\\miniconda3\\lib\\site-packages (from typer-slim->huggingface-hub<2.0,>=0.25.0->datasets) (8.2.1)\n",
      "Downloading datasets-4.6.0-py3-none-any.whl (520 kB)\n",
      "Downloading huggingface_hub-1.4.1-py3-none-any.whl (553 kB)\n",
      "   ---------------------------------------- 0.0/553.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 553.3/553.3 kB 9.4 MB/s  0:00:00\n",
      "Downloading hf_xet-1.3.1-cp37-abi3-win_amd64.whl (3.6 MB)\n",
      "   ---------------------------------------- 0.0/3.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.6/3.6 MB 21.6 MB/s  0:00:00\n",
      "Downloading multiprocess-0.70.18-py312-none-any.whl (150 kB)\n",
      "Downloading xxhash-3.6.0-cp312-cp312-win_amd64.whl (31 kB)\n",
      "Installing collected packages: xxhash, multiprocess, hf-xet, huggingface-hub, datasets\n",
      "\n",
      "   -------- ------------------------------- 1/5 [multiprocess]\n",
      "   -------- ------------------------------- 1/5 [multiprocess]\n",
      "   -------- ------------------------------- 1/5 [multiprocess]\n",
      "   ---------------- ----------------------- 2/5 [hf-xet]\n",
      "   ---------------- ----------------------- 2/5 [hf-xet]\n",
      "   ------------------------ --------------- 3/5 [huggingface-hub]\n",
      "   ------------------------ --------------- 3/5 [huggingface-hub]\n",
      "   ------------------------ --------------- 3/5 [huggingface-hub]\n",
      "   ------------------------ --------------- 3/5 [huggingface-hub]\n",
      "   ------------------------ --------------- 3/5 [huggingface-hub]\n",
      "   ------------------------ --------------- 3/5 [huggingface-hub]\n",
      "   ------------------------ --------------- 3/5 [huggingface-hub]\n",
      "   ------------------------ --------------- 3/5 [huggingface-hub]\n",
      "   ------------------------ --------------- 3/5 [huggingface-hub]\n",
      "   ------------------------ --------------- 3/5 [huggingface-hub]\n",
      "   ------------------------ --------------- 3/5 [huggingface-hub]\n",
      "   ------------------------ --------------- 3/5 [huggingface-hub]\n",
      "   ------------------------ --------------- 3/5 [huggingface-hub]\n",
      "   -------------------------------- ------- 4/5 [datasets]\n",
      "   -------------------------------- ------- 4/5 [datasets]\n",
      "   -------------------------------- ------- 4/5 [datasets]\n",
      "   -------------------------------- ------- 4/5 [datasets]\n",
      "   -------------------------------- ------- 4/5 [datasets]\n",
      "   -------------------------------- ------- 4/5 [datasets]\n",
      "   -------------------------------- ------- 4/5 [datasets]\n",
      "   -------------------------------- ------- 4/5 [datasets]\n",
      "   -------------------------------- ------- 4/5 [datasets]\n",
      "   -------------------------------- ------- 4/5 [datasets]\n",
      "   -------------------------------- ------- 4/5 [datasets]\n",
      "   -------------------------------- ------- 4/5 [datasets]\n",
      "   ---------------------------------------- 5/5 [datasets]\n",
      "\n",
      "Successfully installed datasets-4.6.0 hf-xet-1.3.1 huggingface-hub-1.4.1 multiprocess-0.70.18 xxhash-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e883e7bc-a04c-4eff-aac5-757258808dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b913d357-7e6d-49f3-914e-803ab0ba2599",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aeb3fb9f5f74489a0217d0ba850f514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\playdata2\\miniconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:130: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\playdata2\\.cache\\huggingface\\hub\\datasets--imdb. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8bacdafb8464e8ab5ea5f518fc48bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3208cafa5234acea9762edd1ebc9623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfae8086bff24011affbbd015f5e01fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/unsupervised-00000-of-00001.p(…):   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b24ec54a047a4fe6bf3a1abaca7f19d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d0b4fcb99c47f786dcb297124923ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3d3aace4ed442f94264a52b9d1f7a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "123119b7-ac65-4e83-9f32-7ceb24ec995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d9da30cd-99d0-4759-a9b6-774c6fcdefb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data.dataset import random_split\n",
    "torch.manual_seed(1)\n",
    "train_dataset, valid_dataset = random_split(\n",
    "    list(train_dataset), [20000, 5000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "50e0ddf5-5888-4afe-8948-dac494e331b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter, OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f00e8585-530b-4a7e-841d-2d62be4de79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counts = Counter()\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) +\\\n",
    "        ' '.join(emoticons).replace('-', '')\n",
    "    tokenized = text.split()\n",
    "    return tokenized\n",
    "\n",
    "\n",
    "for data in train_dataset:\n",
    "    tokens = tokenizer(data['text'])\n",
    "    token_counts.update(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "99373229-9af5-4623-aa79-839ebccc4db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69023"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dccd5527-d333-416b-b9ed-5caae1a5974b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_freq_tuples = sorted(token_counts.items(), key=lambda x : x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7e62fb21-1636-4179-95e7-2a68f8630865",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_dict = OrderedDict(sorted_by_freq_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "21ac1e0a-583d-4ab4-a11a-e1960475fec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset = load_dataset(\"imdb\", split=\"train\")\n",
    "df = pd.DataFrame(dataset)\n",
    "df['word_count'] = df['text'].apply(lambda x: len(x.split()))\n",
    "plt.hist(df['word_count'], bins=50, color='skyblue', edgecolor='black')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e98c3764-01d0-45f8-8aa4-84035295354e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\"<pad>\" : 0 , \"<unk>\" : 1}\n",
    "for key, val in enumerate(ordered_dict.keys()):\n",
    "    vocab[val] = key+2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3d558344-7550-4bfd-bc4b-2306978543fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 7, 35, 457]\n"
     ]
    }
   ],
   "source": [
    "print([vocab[token] for token in ['this', 'is', 'an', 'example']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ddc048fb-92f3-421f-a032-0b9bdf72ee6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9727a871-a3ad-4e96-917f-7ee3356123ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "152b256b-2a07-41dd-9ec0-e7600146fa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: [vocab.get(token, 1) for token in tokenizer(x)]\n",
    "label_pipeline = lambda x: float(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bea0c7e5-5c7e-4dbf-b61f-f20dc6beefde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    label_list, text_list, lengths = [], [], []\n",
    "    \n",
    "    for _sample in batch:\n",
    "        _label = _sample['label']\n",
    "        _text = _sample['text']\n",
    "        \n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        \n",
    "        lengths.append(processed_text.size(0))\n",
    "\n",
    "    label_list = torch.tensor(label_list, dtype=torch.float32)\n",
    "    lengths = torch.tensor(lengths, dtype=torch.int64)\n",
    "    padded_text_list = nn.utils.rnn.pad_sequence(\n",
    "        text_list, batch_first=True, padding_value=0\n",
    "    )\n",
    "\n",
    "    return padded_text_list.to(device), label_list.to(device), lengths.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a6eb3fc1-e9ec-43c6-afe9-6331ada12ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                      shuffle=True, collate_fn=collate_batch)\n",
    "valid_dl = DataLoader(valid_dataset, batch_size=batch_size,\n",
    "                      shuffle=False, collate_fn=collate_batch)\n",
    "test_dl = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                     shuffle=False, collate_fn=collate_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bee51a77-3db9-42f2-b9b4-fae9c9826e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_batch, label_batch, length_batch = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3f9e7aa7-5971-491c-ab04-2d47c614f353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([251, 249, 139,  94, 169, 125, 460,  44, 203, 669, 220, 243, 477, 272,\n",
       "        129, 131, 215,  12, 430, 195,  91, 303, 331, 129, 129, 147, 121, 210,\n",
       "        229, 152, 281, 129])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1521cf3f-8631-49fd-8027-c51c19258ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(num_embeddings=10,\n",
    "                         embedding_dim=3,\n",
    "                         padding_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "100b435e-d845-443c-87cf-a60e303fb5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_encoded_input = torch.LongTensor([[1,2,4,5],[4,3,2,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "07be4ac0-eb48-4702-9673-42e5b5950285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.9056,  0.9349,  0.4973],\n",
       "         [-0.9374, -0.6541, -1.2451],\n",
       "         [ 1.2648,  0.2183, -2.2485],\n",
       "         [ 1.0599, -2.2663,  1.3410]],\n",
       "\n",
       "        [[ 1.2648,  0.2183, -2.2485],\n",
       "         [ 0.4607, -0.0680,  0.1856],\n",
       "         [-0.9374, -0.6541, -1.2451],\n",
       "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding(text_encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "09b921cb-de4a-464a-936c-5eb79dc91b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers=2, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, hidden = self.rnn(x)\n",
    "        out = hidden[-1, :, :]\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2ebcfcd6-6154-4a69-bb9b-a4f1391f23bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(64, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d40429ec-5480-47af-937d-d2b64814e31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): RNN(64, 32, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a6898a95-5822-47cd-a8dc-a3c61f514099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0215],\n",
       "        [0.6220],\n",
       "        [0.2509],\n",
       "        [0.2779],\n",
       "        [0.2444]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randn(5,3,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "eecf457a-01d5-4750-baaa-e1b016c727a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size,\n",
    "                                      embed_dim,\n",
    "                                      padding_idx=0)\n",
    "        self.rnn = nn.RNN(embed_dim, rnn_hidden_size,\n",
    "                           batch_first=True)\n",
    "        self.fc1 = nn.Linear(rnn_hidden_size, fc_hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(fc_hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, text, lengths):\n",
    "        out = self.embedding(text)\n",
    "        out = nn.utils.rnn.pack_padded_sequence(out, lengths.cpu().numpy(), enforce_sorted=False, batch_first=True)\n",
    "        out, (hidden, cell) = self.rnn(out)\n",
    "        out = hidden[-1, :, :]\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "963bb35e-5ddb-428b-830b-8db144f54dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embed_dim = 20\n",
    "rnn_hidden_size = 64\n",
    "fc_hidden_size = 64\n",
    "\n",
    "torch.manual_seed(1)\n",
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size)\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "98cbcd73-fd83-425d-bf53-2361afdba074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    for text_batch, label_batch, lengths in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(text_batch, lengths)[:, 0]\n",
    "        loss = loss_fn(pred, label_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_acc += ((pred>=0.5).float() == label_batch).float().sum().item()\n",
    "        total_loss += loss.item()*label_batch.size(0)\n",
    "    return total_acc/len(dataloader.dataset), total_loss/len(dataloader.dataset)\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for text_batch, label_batch, lengths in dataloader:\n",
    "            pred = model(text_batch, lengths)[:, 0]\n",
    "            loss = loss_fn(pred, label_batch)\n",
    "            total_acc += ((pred>=0.5).float() == label_batch).float().sum().item()\n",
    "            total_loss += loss.item()*label_batch.size(0)\n",
    "    return total_acc/len(list(dataloader.dataset)), total_loss/len(list(dataloader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7a692a10-5f75-4f18-8225-ae2f694ff339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch -> 0\n",
      "에포크 0 정확도: 0.5486 검증 정확도: 0.5480\n",
      "epoch -> 1\n",
      "에포크 1 정확도: 0.6018 검증 정확도: 0.5866\n",
      "epoch -> 2\n",
      "에포크 2 정확도: 0.6575 검증 정확도: 0.6040\n",
      "epoch -> 3\n",
      "에포크 3 정확도: 0.6922 검증 정확도: 0.7028\n",
      "epoch -> 4\n",
      "에포크 4 정확도: 0.7594 검증 정확도: 0.7366\n",
      "epoch -> 5\n",
      "에포크 5 정확도: 0.7800 검증 정확도: 0.7296\n",
      "epoch -> 6\n",
      "에포크 6 정확도: 0.7921 검증 정확도: 0.6564\n",
      "epoch -> 7\n",
      "에포크 7 정확도: 0.7947 검증 정확도: 0.7610\n",
      "epoch -> 8\n",
      "에포크 8 정확도: 0.8041 검증 정확도: 0.6914\n",
      "epoch -> 9\n",
      "에포크 9 정확도: 0.8325 검증 정확도: 0.7176\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"epoch -> {epoch}\")\n",
    "    acc_train, loss_train = train(train_dl)\n",
    "    acc_valid, loss_valid = evaluate(valid_dl)\n",
    "    print(f'에포크 {epoch} 정확도: {acc_train:.4f} 검증 정확도: {acc_valid:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0de2bf9a-6853-46b7-a206-c5f7ac781cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size,\n",
    "                                      embed_dim,\n",
    "                                      padding_idx=0)\n",
    "        # self.rnn = nn.RNN(embed_dim, rnn_hidden_size,\n",
    "        #                    batch_first=True)\n",
    "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size,\n",
    "                           batch_first=True)\n",
    "        self.fc1 = nn.Linear(rnn_hidden_size, fc_hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(fc_hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, text, lengths):\n",
    "        out = self.embedding(text)\n",
    "        out = nn.utils.rnn.pack_padded_sequence(out, lengths.cpu().numpy(), enforce_sorted=False, batch_first=True)\n",
    "        # out, hidden = self.rnn(out\n",
    "        out, (hidden, cell) = self.rnn(out)\n",
    "        out = hidden[-1, :, :]\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3083296c-6472-4d7a-b8d8-c79ad0761d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embed_dim = 20\n",
    "rnn_hidden_size = 64\n",
    "fc_hidden_size = 64\n",
    "\n",
    "torch.manual_seed(1)\n",
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size)\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bd846856-7764-4696-9657-30acb534885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    for text_batch, label_batch, lengths in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(text_batch, lengths)[:, 0]\n",
    "        loss = loss_fn(pred, label_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_acc += ((pred>=0.5).float() == label_batch).float().sum().item()\n",
    "        total_loss += loss.item()*label_batch.size(0)\n",
    "    return total_acc/len(dataloader.dataset), total_loss/len(dataloader.dataset)\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for text_batch, label_batch, lengths in dataloader:\n",
    "            pred = model(text_batch, lengths)[:, 0]\n",
    "            loss = loss_fn(pred, label_batch)\n",
    "            total_acc += ((pred>=0.5).float() == label_batch).float().sum().item()\n",
    "            total_loss += loss.item()*label_batch.size(0)\n",
    "    return total_acc/len(list(dataloader.dataset)), total_loss/len(list(dataloader.dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4d07539c-9339-407d-86e0-ce0c6e267684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch -> 0\n",
      "에포크 0 정확도: 0.6062 검증 정확도: 0.6584\n",
      "epoch -> 1\n",
      "에포크 1 정확도: 0.7053 검증 정확도: 0.7248\n",
      "epoch -> 2\n",
      "에포크 2 정확도: 0.7958 검증 정확도: 0.7960\n",
      "epoch -> 3\n",
      "에포크 3 정확도: 0.8475 검증 정확도: 0.7746\n",
      "epoch -> 4\n",
      "에포크 4 정확도: 0.8700 검증 정확도: 0.8178\n",
      "epoch -> 5\n",
      "에포크 5 정확도: 0.8898 검증 정확도: 0.8006\n",
      "epoch -> 6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[122]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[32m      9\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mepoch -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     acc_train, loss_train = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     acc_valid, loss_valid = evaluate(valid_dl)\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m에포크 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m 정확도: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_train\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m 검증 정확도: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_valid\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[120]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(dataloader)\u001b[39m\n\u001b[32m      6\u001b[39m pred = model(text_batch, lengths)[:, \u001b[32m0\u001b[39m]\n\u001b[32m      7\u001b[39m loss = loss_fn(pred, label_batch)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m optimizer.step()\n\u001b[32m     10\u001b[39m total_acc += ((pred>=\u001b[32m0.5\u001b[39m).float() == label_batch).float().sum().item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\torch\\_tensor.py:630\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    620\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    621\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    622\u001b[39m         Tensor.backward,\n\u001b[32m    623\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    628\u001b[39m         inputs=inputs,\n\u001b[32m    629\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:364\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    359\u001b[39m     retain_graph = create_graph\n\u001b[32m    361\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    362\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    363\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\torch\\autograd\\graph.py:865\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    863\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    864\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m865\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    866\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    869\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"epoch -> {epoch}\")\n",
    "    acc_train, loss_train = train(train_dl)\n",
    "    acc_valid, loss_valid = evaluate(valid_dl)\n",
    "    print(f'에포크 {epoch} 정확도: {acc_train:.4f} 검증 정확도: {acc_valid:.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f49218-1f4c-45e7-88ab-7f087ae0893b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
